{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e82cc851-5123-4938-90da-4c2c69cb9fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8 MB 5.3 MB/s eta 0:00:01     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.5 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.2.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/miniconda3/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.9/site-packages (from wandb) (58.0.4)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 145 kB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /opt/miniconda3/lib/python3.9/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/dhoof/.local/lib/python3.9/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/dhoof/.local/lib/python3.9/site-packages (from wandb) (3.1.27)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/miniconda3/lib/python3.9/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: PyYAML in /home/dhoof/.local/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/miniconda3/lib/python3.9/site-packages (from wandb) (2.27.1)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/dhoof/.local/lib/python3.9/site-packages (from wandb) (3.20.1)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/dhoof/.local/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/dhoof/.local/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Building wheels for collected packages: promise, pathtools\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=ffef2440240c6f85fe6c85171e4661d052c0dda5a9330a9f1791ba8ba929f6e0\n",
      "  Stored in directory: /home/dhoof/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=674b6862a1d79984f5d3b58b3591e2f8bb1b83661f99766ecbdfbb9eb6fb177c\n",
      "  Stored in directory: /home/dhoof/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
      "Successfully built promise pathtools\n",
      "Installing collected packages: shortuuid, setproctitle, sentry-sdk, promise, pathtools, docker-pycreds, wandb\n",
      "\u001b[33m  WARNING: The script shortuuid is installed in '/home/dhoof/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts wandb and wb are installed in '/home/dhoof/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed docker-pycreds-0.4.0 pathtools-0.1.2 promise-2.3 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 wandb-0.12.16\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797c59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import glob\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85fa6416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhoof\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhoof\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhoof\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhoof\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./output/cifar10/lowres_resnet9/version_1/wandb/run-20220601_124953-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhoof/3005FineTuninglowres_resnet9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhoof/3005FineTuninglowres_resnet9/runs/1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./output/cifar10/lowres_densenet121/version_1/wandb/run-20220601_124953-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhoof/3005FineTuninglowres_densenet121\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhoof/3005FineTuninglowres_densenet121/runs/1\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./output/cifar10/lowres_resnet50/version_1/wandb/run-20220601_124954-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhoof/3005FineTuninglowres_resnet50\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhoof/3005FineTuninglowres_resnet50/runs/1\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./output/cifar10/lowres_vgg16_bn/version_1/wandb/run-20220601_124954-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dhoof/3005FineTuninglowres_vgg16_bn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dhoof/3005FineTuninglowres_vgg16_bn/runs/1\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    }
   ],
   "source": [
    "checkpoints=[\n",
    "    {'dataset_trained_on':'cifar10','version': 0},\n",
    "    {'dataset_trained_on':'cifar100','version': 0},\n",
    "    {'dataset_trained_on':'grocerystore','version': 0},\n",
    "    {'dataset_trained_on':'histaerial25x25','version': 0},\n",
    "    {'dataset_trained_on':'histaerial50x50','version': 0},\n",
    "    {'dataset_trained_on':'svhn','version': 0},\n",
    "    {'dataset_trained_on':'tinyimagenet','version': 0},\n",
    "            ]\n",
    "\n",
    "# models_todo = ['lowres_resnet9','lowres_resnet50','lowres_densenet121','lowres_vgg16_bn']\n",
    "models_todo = ['lowres_resnet9','lowres_resnet50','lowres_densenet121','lowres_vgg16_bn']\n",
    "# models_todo = ['lowres_resnet9','lowres_resnet50']\n",
    "data_todo = ['cifar10']\n",
    "# data_todo = ['histaerial25x25']\n",
    "# data_todo = ['cifar10']\n",
    "gpus = [0,1,2,3]\n",
    "workers_per_gpu = 1\n",
    "queue_models_per_gpu=True\n",
    "\n",
    "#!python pytorch-pretrained-cnns/train.py --classifier $model --dataset $dataset --batch_size 512 --gpu_id $gpu --num_workers 4 --scheduler \"Step\" --max_epochs 150 --checkpoints \"last_best\" --wandb $wandbname 1> /dev/null\n",
    "\n",
    "# hparams_path_json = create_hparams(glob.glob(f\"output/{checkpoint['dataset_trained_on']}/{model}/version_{checkpoint['version']}/hparams.yaml\")[0])  \n",
    "        # --params $hparams_path_json \\\n",
    "\n",
    "def gpu_worker(gpu, q):\n",
    "    while not q.empty():\n",
    "        (checkpoint, model, dataset) = q.get()    \n",
    "        if queue_models_per_gpu:\n",
    "            wandbname=(\"3005FineTuning\"+str(model)).strip(\"_\")\n",
    "        else:\n",
    "            wandbname=(\"2405CH\"+str(checkpoint['dataset_trained_on'])+str(model)+str(dataset)).strip(\"_\")\n",
    "            \n",
    "        checkpoint_name = glob.glob(f\"output/{checkpoint['dataset_trained_on']}/{model}/version_{checkpoint['version']}/checkpoints/*.ckpt\")[0]        \n",
    "        !python pytorch-pretrained-cnns/train.py \\\n",
    "        --classifier $model \\\n",
    "        --dataset $dataset \\\n",
    "        --optimizer \"adam\" \\\n",
    "        --load_checkpoint $checkpoint_name \\\n",
    "        --replace_fc True \\\n",
    "        --learning_rate 1e-5 \\\n",
    "        --gpu_id $gpu \\\n",
    "        --num_workers 4 \\\n",
    "        --scheduler \"None\" \\\n",
    "        --max_epochs 20 \\\n",
    "        --batch_size 128 \\\n",
    "        --checkpoints \"last_best\" \\\n",
    "        --wandb $wandbname 1> /dev/null\n",
    "\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    if queue_models_per_gpu:\n",
    "        if len(gpus) != len(models_todo):\n",
    "            raise ValueError(\"Models have to be same amout of gpus\")\n",
    "        queues=dict()\n",
    "        for gpu, model in zip(gpus,models_todo):\n",
    "            queues[model]=(gpu,mp.Queue())        \n",
    "        \n",
    "        for checkpoint in checkpoints:\n",
    "            for model_name in models_todo:\n",
    "                for ds in data_todo:\n",
    "                    queues[model_name][1].put((checkpoint, model_name, ds))        \n",
    "        \n",
    "        processes = []\n",
    "        for model in models_todo:            \n",
    "            p = mp.Process(target=gpu_worker, args=queues[model])\n",
    "            p.start()\n",
    "            processes.append(p)        \n",
    "        \n",
    "    else:\n",
    "        que = mp.Queue()\n",
    "        for checkpoint in checkpoints:\n",
    "            for model_name in models_todo:\n",
    "                for ds in data_todo:\n",
    "                    que.put((checkpoint, model_name, ds))\n",
    "\n",
    "        processes = []\n",
    "        for gpu in gpus * workers_per_gpu:\n",
    "            p = mp.Process(target=gpu_worker, args=(gpu, que))\n",
    "            p.start()\n",
    "            processes.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc149fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in processes:\n",
    "    p.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab46ca9-8e5c-462a-85e5-651e43e32757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m1/118\u001b[0m \u001b[37m0:00:03 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 2.41 v_num: \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m2/118\u001b[0m \u001b[37m0:00:03 â€¢ 0:00:09\u001b[0m \u001b[37m12.94it/s\u001b[0m \u001b[37mloss: 2.41 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m2/118\u001b[0m \u001b[37m0:00:03 â€¢ 0:00:09\u001b[0m \u001b[37m12.94it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m3/118\u001b[0m \u001b[37m0:00:03 â€¢ 0:00:09\u001b[0m \u001b[37m13.09it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m3/118\u001b[0m \u001b[37m0:00:03 â€¢ 0:00:09\u001b[0m \u001b[37m13.09it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m4/118\u001b[0m \u001b[37m0:00:03 â€¢ 0:00:10\u001b[0m \u001b[37m12.60it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m4/118\u001b[0m \u001b[37m0:00:03 â€¢ 0:00:10\u001b[0m \u001b[37m12.60it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m5/118\u001b[0m \u001b[37m0:00:03 â€¢ 0:00:09\u001b[0m \u001b[37m12.59it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m5/118\u001b[0m \u001b[37m0:00:03 â€¢ 0:00:09\u001b[0m \u001b[37m12.59it/s\u001b[0m \u001b[37mloss: 2.4 v_num: \u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m6/118\u001b[0m \u001b[37m0:00:03 â€¢ 0:00:10\u001b[0m \u001b[37m12.21it/s\u001b[0m \u001b[37mloss: 2.4 v_num: \u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m6/118\u001b[0m \u001b[37m0:00:03 â€¢ 0:00:10\u001b[0m \u001b[37m12.21it/s\u001b[0m \u001b[37mloss: 2.4 v_num: \u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m7/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:10\u001b[0m \u001b[37m12.15it/s\u001b[0m \u001b[37mloss: 2.4 v_num: \u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m7/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:10\u001b[0m \u001b[37m12.15it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m8/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:10\u001b[0m \u001b[37m12.12it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m8/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:10\u001b[0m \u001b[37m12.12it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m9/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:10\u001b[0m \u001b[37m12.02it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m9/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:10\u001b[0m \u001b[37m12.02it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m12.01it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m12.01it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m11/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:10\u001b[0m \u001b[37m11.87it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m11/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:10\u001b[0m \u001b[37m11.87it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m12/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.79it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m12/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.79it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m13/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.98it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m13/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.98it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m14/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.95it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m14/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.95it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m15/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.96it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m15/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.96it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m16/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.89it/s\u001b[0m \u001b[37mloss: 2.39 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m16/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.89it/s\u001b[0m \u001b[37mloss: 2.38 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m17/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.92it/s\u001b[0m \u001b[37mloss: 2.38 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m17/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.92it/s\u001b[0m \u001b[37mloss: 2.38 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m18/118\u001b[0m \u001b[37m0:00:04 â€¢ 0:00:09\u001b[0m \u001b[37m11.93it/s\u001b[0m \u001b[37mloss: 2.38 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m18/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.93it/s\u001b[0m \u001b[37mloss: 2.38 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m19/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.90it/s\u001b[0m \u001b[37mloss: 2.38 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m19/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.90it/s\u001b[0m \u001b[37mloss: 2.38 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.88it/s\u001b[0m \u001b[37mloss: 2.38 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.88it/s\u001b[0m \u001b[37mloss: 2.38 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m21/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.85it/s\u001b[0m \u001b[37mloss: 2.38 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m21/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.85it/s\u001b[0m \u001b[37mloss: 2.37 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m22/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.37 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m22/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.37 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m23/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.85it/s\u001b[0m \u001b[37mloss: 2.37 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m23/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:09\u001b[0m \u001b[37m11.85it/s\u001b[0m \u001b[37mloss: 2.37 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m24/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.83it/s\u001b[0m \u001b[37mloss: 2.37 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m24/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.83it/s\u001b[0m \u001b[37mloss: 2.36 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m25/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.86it/s\u001b[0m \u001b[37mloss: 2.36 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m25/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.86it/s\u001b[0m \u001b[37mloss: 2.36 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m26/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.36 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m26/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.36 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m27/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.85it/s\u001b[0m \u001b[37mloss: 2.36 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m27/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.85it/s\u001b[0m \u001b[37mloss: 2.36 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m28/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.36 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m28/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.35 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m29/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.35 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m29/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.35 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/118\u001b[0m \u001b[37m0:00:05 â€¢ 0:00:08\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.35 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/118\u001b[0m \u001b[37m0:00:06 â€¢ 0:00:08\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.35 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "                                                               \u001b[37m10.938           \u001b[0m^C\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K/home/dhoof/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer\n",
      ".py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful \n",
      "shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/118\u001b[0m \u001b[37m0:00:06 â€¢ 0:00:08\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.35 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0   \u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/118\u001b[0m \u001b[37m0:00:06 â€¢ 0:00:08\u001b[0m \u001b[37m11.84it/s\u001b[0m \u001b[37mloss: 2.35 v_num:\u001b[0m\n",
      "                                                               \u001b[37m4 acc/train:     \u001b[0m\n",
      "                                                               \u001b[37m10.938           \u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!python pytorch-pretrained-cnns/train.py \\\n",
    "        --classifier \"lowres_vgg16_bn\" \\\n",
    "        --dataset \"cifar10\" \\\n",
    "        --load_checkpoint \"output/tinyimagenet/lowres_vgg16_bn/version_0/checkpoints/epoch=133-step=52259.ckpt\" \\\n",
    "        --replace_fc True \\\n",
    "        --learning_rate 1e-2 \\\n",
    "        --gpu_id 0 \\\n",
    "        --num_workers 8 \\\n",
    "        --scheduler \"None\" \\\n",
    "        --max_epochs 15 \\\n",
    "        --checkpoints \"last_best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c054ea-a370-4eeb-ad76-01931c498f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
